{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q279fLKbL8Le",
        "outputId": "b5ac03ee-0ec5-4d80-8b3c-47f956c11b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video...\n",
            "Processed 30 frames...\n",
            "Processed 60 frames...\n",
            "Processed 90 frames...\n",
            "Processed 120 frames...\n",
            "Processed 150 frames...\n",
            "Processed 180 frames...\n",
            "Processed 210 frames...\n",
            "Processed 240 frames...\n",
            "Processed 270 frames...\n",
            "Processed 300 frames...\n",
            "Processed 330 frames...\n",
            "Processed 360 frames...\n",
            "Processed 390 frames...\n",
            "Processed 420 frames...\n",
            "Processed 450 frames...\n",
            "Processed 480 frames...\n",
            "Processed 510 frames...\n",
            "Processed 540 frames...\n",
            "Processed 570 frames...\n",
            "Processed 600 frames...\n",
            "Processed 630 frames...\n",
            "Processed 660 frames...\n",
            "Processed 690 frames...\n",
            "Processed 720 frames...\n",
            "Processed 750 frames...\n",
            "Processed 780 frames...\n",
            "Processed 810 frames...\n",
            "Processed 840 frames...\n",
            "Processed 870 frames...\n",
            "Processed 900 frames...\n",
            "Processed 930 frames...\n",
            "Processed 960 frames...\n",
            "Processed 990 frames...\n",
            "Processed 1020 frames...\n",
            "Processed 1050 frames...\n",
            "Processed 1080 frames...\n",
            "Processed 1110 frames...\n",
            "Processed 1140 frames...\n",
            "Processed 1170 frames...\n",
            "Processed 1200 frames...\n",
            "Processed 1230 frames...\n",
            "Processed 1260 frames...\n",
            "Processed 1290 frames...\n",
            "Processed 1320 frames...\n",
            "Processed 1350 frames...\n",
            "Processed 1380 frames...\n",
            "Processed 1410 frames...\n",
            "Processed 1440 frames...\n",
            "Processed 1470 frames...\n",
            "Processed 1500 frames...\n",
            "Processed 1530 frames...\n",
            "Processed 1560 frames...\n",
            "Processed 1590 frames...\n",
            "Processed 1620 frames...\n",
            "Processed 1650 frames...\n",
            "Processed 1680 frames...\n",
            "Processed 1710 frames...\n",
            "Processed 1740 frames...\n",
            "Processed 1770 frames...\n",
            "Processed 1800 frames...\n",
            "Processed 1830 frames...\n",
            "Processed 1860 frames...\n",
            "Processed 1890 frames...\n",
            "Processed 1920 frames...\n",
            "Processed 1950 frames...\n",
            "Processed 1980 frames...\n",
            "Processed 2010 frames...\n",
            "Processed 2040 frames...\n",
            "Processed 2070 frames...\n",
            "\n",
            "Processing complete!\n",
            "Output saved to: tracked_dance.mp4\n",
            "Movement data saved to: movement_data.json\n",
            "\n",
            "=== Movement Analysis ===\n",
            "Total frames analyzed: 1843\n",
            "Average movement velocity: 1.1243\n",
            "Peak movement velocity: 26.6460\n",
            "Min movement velocity: 0.0000\n",
            "\n",
            "Top 5 most active moments (by timestamp):\n",
            "  1. 69.20s - velocity: 26.6460\n",
            "  2. 60.47s - velocity: 23.2363\n",
            "  3. 44.73s - velocity: 20.7428\n",
            "  4. 28.13s - velocity: 20.6327\n",
            "  5. 21.20s - velocity: 19.8842\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "class DanceTracker:\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = video_path\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5\n",
        "        )\n",
        "        self.movement_data = []\n",
        "\n",
        "    def calculate_velocity(self, prev_landmarks, curr_landmarks):\n",
        "        \"\"\"Calculate movement velocity between frames\"\"\"\n",
        "        if prev_landmarks is None:\n",
        "            return 0\n",
        "\n",
        "        total_movement = 0\n",
        "        for i in range(len(curr_landmarks)):\n",
        "            prev = np.array([prev_landmarks[i].x, prev_landmarks[i].y])\n",
        "            curr = np.array([curr_landmarks[i].x, curr_landmarks[i].y])\n",
        "            total_movement += np.linalg.norm(curr - prev)\n",
        "\n",
        "        return total_movement\n",
        "\n",
        "    def get_joint_angles(self, landmarks):\n",
        "        \"\"\"Calculate key joint angles\"\"\"\n",
        "        def angle_between(p1, p2, p3):\n",
        "            v1 = np.array([p1.x - p2.x, p1.y - p2.y])\n",
        "            v2 = np.array([p3.x - p2.x, p3.y - p2.y])\n",
        "\n",
        "            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
        "            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
        "            return np.degrees(angle)\n",
        "\n",
        "        angles = {}\n",
        "        # Right elbow\n",
        "        angles['right_elbow'] = angle_between(\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
        "        )\n",
        "        # Left elbow\n",
        "        angles['left_elbow'] = angle_between(\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
        "        )\n",
        "        # Right knee\n",
        "        angles['right_knee'] = angle_between(\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
        "        )\n",
        "        # Left knee\n",
        "        angles['left_knee'] = angle_between(\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "            landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
        "        )\n",
        "\n",
        "        return angles\n",
        "\n",
        "    def process_video(self, output_path='output_dance.mp4', save_data=True):\n",
        "        \"\"\"Process video and track dance movements\"\"\"\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        prev_landmarks = None\n",
        "\n",
        "        print(\"Processing video...\")\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = self.pose.process(rgb_frame)\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                # Draw pose landmarks\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    frame,\n",
        "                    results.pose_landmarks,\n",
        "                    self.mp_pose.POSE_CONNECTIONS,\n",
        "                    self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
        "                    self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
        "                )\n",
        "\n",
        "                landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "                # Calculate velocity\n",
        "                velocity = self.calculate_velocity(prev_landmarks, landmarks)\n",
        "\n",
        "                # Get joint angles\n",
        "                angles = self.get_joint_angles(landmarks)\n",
        "\n",
        "                # Store movement data\n",
        "                frame_data = {\n",
        "                    'frame': frame_count,\n",
        "                    'velocity': float(velocity),\n",
        "                    'angles': angles,\n",
        "                    'timestamp': frame_count / fps\n",
        "                }\n",
        "                self.movement_data.append(frame_data)\n",
        "\n",
        "                # Display info on frame\n",
        "                cv2.putText(frame, f'Frame: {frame_count}', (10, 30),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "                cv2.putText(frame, f'Movement: {velocity:.3f}', (10, 60),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "                prev_landmarks = landmarks\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "            if frame_count % 30 == 0:\n",
        "                print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(f\"\\nProcessing complete!\")\n",
        "        print(f\"Output saved to: {output_path}\")\n",
        "\n",
        "        # Save movement data\n",
        "        if save_data:\n",
        "            data_file = 'movement_data.json'\n",
        "            with open(data_file, 'w') as f:\n",
        "                json.dump(self.movement_data, f, indent=2)\n",
        "            print(f\"Movement data saved to: {data_file}\")\n",
        "\n",
        "        self.analyze_movements()\n",
        "\n",
        "    def analyze_movements(self):\n",
        "        \"\"\"Analyze and summarize movement patterns\"\"\"\n",
        "        if not self.movement_data:\n",
        "            print(\"No movement data to analyze\")\n",
        "            return\n",
        "\n",
        "        velocities = [d['velocity'] for d in self.movement_data]\n",
        "\n",
        "        print(\"\\n=== Movement Analysis ===\")\n",
        "        print(f\"Total frames analyzed: {len(self.movement_data)}\")\n",
        "        print(f\"Average movement velocity: {np.mean(velocities):.4f}\")\n",
        "        print(f\"Peak movement velocity: {np.max(velocities):.4f}\")\n",
        "        print(f\"Min movement velocity: {np.min(velocities):.4f}\")\n",
        "\n",
        "        # Find most active moments\n",
        "        sorted_data = sorted(self.movement_data, key=lambda x: x['velocity'], reverse=True)\n",
        "        print(\"\\nTop 5 most active moments (by timestamp):\")\n",
        "        for i, data in enumerate(sorted_data[:5], 1):\n",
        "            print(f\"  {i}. {data['timestamp']:.2f}s - velocity: {data['velocity']:.4f}\")\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    tracker = DanceTracker('dance.mp4')\n",
        "    tracker.process_video(output_path='tracked_dance.mp4', save_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "class MultiPersonDanceTracker:\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = video_path\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        # Enable tracking for multiple people\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=2,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5\n",
        "        )\n",
        "        self.movement_data = defaultdict(list)\n",
        "        self.person_colors = {}\n",
        "\n",
        "    def generate_color(self, person_id):\n",
        "        \"\"\"Generate unique color for each person\"\"\"\n",
        "        if person_id not in self.person_colors:\n",
        "            np.random.seed(person_id * 42)\n",
        "            self.person_colors[person_id] = tuple(np.random.randint(50, 255, 3).tolist())\n",
        "        return self.person_colors[person_id]\n",
        "\n",
        "    def calculate_velocity(self, prev_landmarks, curr_landmarks):\n",
        "        \"\"\"Calculate movement velocity between frames\"\"\"\n",
        "        if prev_landmarks is None:\n",
        "            return 0\n",
        "\n",
        "        total_movement = 0\n",
        "        for i in range(min(len(prev_landmarks), len(curr_landmarks))):\n",
        "            prev = np.array([prev_landmarks[i].x, prev_landmarks[i].y])\n",
        "            curr = np.array([curr_landmarks[i].x, curr_landmarks[i].y])\n",
        "            total_movement += np.linalg.norm(curr - prev)\n",
        "\n",
        "        return total_movement\n",
        "\n",
        "    def get_bounding_box(self, landmarks, width, height):\n",
        "        \"\"\"Get bounding box for a person\"\"\"\n",
        "        x_coords = [lm.x * width for lm in landmarks]\n",
        "        y_coords = [lm.y * height for lm in landmarks]\n",
        "\n",
        "        return {\n",
        "            'x': int(min(x_coords)),\n",
        "            'y': int(min(y_coords)),\n",
        "            'w': int(max(x_coords) - min(x_coords)),\n",
        "            'h': int(max(y_coords) - min(y_coords)),\n",
        "            'center_x': int(np.mean(x_coords)),\n",
        "            'center_y': int(np.mean(y_coords))\n",
        "        }\n",
        "\n",
        "    def get_joint_angles(self, landmarks):\n",
        "        \"\"\"Calculate key joint angles\"\"\"\n",
        "        def angle_between(p1, p2, p3):\n",
        "            v1 = np.array([p1.x - p2.x, p1.y - p2.y])\n",
        "            v2 = np.array([p3.x - p2.x, p3.y - p2.y])\n",
        "\n",
        "            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
        "            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
        "            return np.degrees(angle)\n",
        "\n",
        "        angles = {}\n",
        "        try:\n",
        "            angles['right_elbow'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
        "            )\n",
        "            angles['left_elbow'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
        "            )\n",
        "            angles['right_knee'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
        "            )\n",
        "            angles['left_knee'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return angles\n",
        "\n",
        "    def match_person(self, bbox, prev_people, threshold=100):\n",
        "        \"\"\"Match detected person to previous frame using position\"\"\"\n",
        "        if not prev_people:\n",
        "            return len(prev_people)\n",
        "\n",
        "        min_dist = float('inf')\n",
        "        matched_id = None\n",
        "\n",
        "        for person_id, prev_bbox in prev_people.items():\n",
        "            dist = np.sqrt(\n",
        "                (bbox['center_x'] - prev_bbox['center_x'])**2 +\n",
        "                (bbox['center_y'] - prev_bbox['center_y'])**2\n",
        "            )\n",
        "            if dist < min_dist and dist < threshold:\n",
        "                min_dist = dist\n",
        "                matched_id = person_id\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = max(prev_people.keys()) + 1 if prev_people else 0\n",
        "\n",
        "        return matched_id\n",
        "\n",
        "    def process_video(self, output_path='output_multiperson_dance.mp4', save_data=True):\n",
        "        \"\"\"Process video and track multiple dancers\"\"\"\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        prev_people = {}\n",
        "        prev_landmarks = {}\n",
        "\n",
        "        print(\"Processing video with multiple person tracking...\")\n",
        "        print(\"Note: For best results with many people, consider using YOLO + pose estimation\")\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Process frame in tiles for better multi-person detection\n",
        "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Detect poses (MediaPipe detects one person per frame)\n",
        "            # For true multi-person, we'd need to split frame or use YOLO\n",
        "            results = self.pose.process(rgb_frame)\n",
        "\n",
        "            current_people = {}\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                landmarks = results.pose_landmarks.landmark\n",
        "                bbox = self.get_bounding_box(landmarks, width, height)\n",
        "\n",
        "                # Match to existing person\n",
        "                person_id = self.match_person(bbox, prev_people)\n",
        "                current_people[person_id] = bbox\n",
        "\n",
        "                # Get color for this person\n",
        "                color = self.generate_color(person_id)\n",
        "\n",
        "                # Draw pose landmarks\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    frame,\n",
        "                    results.pose_landmarks,\n",
        "                    self.mp_pose.POSE_CONNECTIONS,\n",
        "                    self.mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2),\n",
        "                    self.mp_drawing.DrawingSpec(color=color, thickness=2)\n",
        "                )\n",
        "\n",
        "                # Calculate velocity\n",
        "                velocity = self.calculate_velocity(\n",
        "                    prev_landmarks.get(person_id),\n",
        "                    landmarks\n",
        "                )\n",
        "\n",
        "                # Get joint angles\n",
        "                angles = self.get_joint_angles(landmarks)\n",
        "\n",
        "                # Store movement data\n",
        "                frame_data = {\n",
        "                    'frame': frame_count,\n",
        "                    'person_id': person_id,\n",
        "                    'velocity': float(velocity),\n",
        "                    'angles': angles,\n",
        "                    'bbox': bbox,\n",
        "                    'timestamp': frame_count / fps\n",
        "                }\n",
        "                self.movement_data[person_id].append(frame_data)\n",
        "\n",
        "                # Draw bounding box and label\n",
        "                cv2.rectangle(frame,\n",
        "                            (bbox['x'], bbox['y']),\n",
        "                            (bbox['x'] + bbox['w'], bbox['y'] + bbox['h']),\n",
        "                            color, 2)\n",
        "                cv2.putText(frame, f'Person {person_id}',\n",
        "                           (bbox['x'], bbox['y'] - 10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "                cv2.putText(frame, f'Vel: {velocity:.2f}',\n",
        "                           (bbox['x'], bbox['y'] + bbox['h'] + 20),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                prev_landmarks[person_id] = landmarks\n",
        "\n",
        "            # Display frame info\n",
        "            cv2.putText(frame, f'Frame: {frame_count} | People: {len(current_people)}',\n",
        "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "            prev_people = current_people\n",
        "            out.write(frame)\n",
        "\n",
        "            if frame_count % 30 == 0:\n",
        "                print(f\"Processed {frame_count} frames, tracking {len(self.movement_data)} people...\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(f\"\\nProcessing complete!\")\n",
        "        print(f\"Output saved to: {output_path}\")\n",
        "        print(f\"Total people tracked: {len(self.movement_data)}\")\n",
        "\n",
        "        # Save movement data\n",
        "        if save_data:\n",
        "            data_file = 'multiperson_movement_data.json'\n",
        "            with open(data_file, 'w') as f:\n",
        "                json.dump(dict(self.movement_data), f, indent=2)\n",
        "            print(f\"Movement data saved to: {data_file}\")\n",
        "\n",
        "        self.analyze_movements()\n",
        "\n",
        "    def analyze_movements(self):\n",
        "        \"\"\"Analyze and summarize movement patterns for all people\"\"\"\n",
        "        if not self.movement_data:\n",
        "            print(\"No movement data to analyze\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n=== Multi-Person Movement Analysis ===\")\n",
        "        print(f\"Total people tracked: {len(self.movement_data)}\")\n",
        "\n",
        "        for person_id, data in self.movement_data.items():\n",
        "            velocities = [d['velocity'] for d in data]\n",
        "\n",
        "            print(f\"\\n--- Person {person_id} ---\")\n",
        "            print(f\"Frames tracked: {len(data)}\")\n",
        "            print(f\"Average movement: {np.mean(velocities):.4f}\")\n",
        "            print(f\"Peak movement: {np.max(velocities):.4f}\")\n",
        "            print(f\"Total activity time: {len(data) / 30:.2f}s\")\n",
        "\n",
        "            # Find most active moment\n",
        "            most_active = max(data, key=lambda x: x['velocity'])\n",
        "            print(f\"Most active at: {most_active['timestamp']:.2f}s\")\n",
        "\n",
        "        # Compare all dancers\n",
        "        print(\"\\n=== Dancer Comparison ===\")\n",
        "        avg_movements = {pid: np.mean([d['velocity'] for d in data])\n",
        "                        for pid, data in self.movement_data.items()}\n",
        "\n",
        "        sorted_dancers = sorted(avg_movements.items(), key=lambda x: x[1], reverse=True)\n",
        "        print(\"Ranking by average movement intensity:\")\n",
        "        for rank, (pid, avg_vel) in enumerate(sorted_dancers, 1):\n",
        "            print(f\"  {rank}. Person {pid}: {avg_vel:.4f}\")\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    tracker = MultiPersonDanceTracker('dance.mp4')\n",
        "    tracker.process_video(output_path='tracked_multiperson_dance.mp4', save_data=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp4cK4p9Nn8A",
        "outputId": "2ca861aa-f76c-4d35-950a-80e60081af76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.12/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n",
            "Processing video with multiple person tracking...\n",
            "Note: For best results with many people, consider using YOLO + pose estimation\n",
            "Processed 30 frames, tracking 4 people...\n",
            "Processed 60 frames, tracking 4 people...\n",
            "Processed 90 frames, tracking 4 people...\n",
            "Processed 120 frames, tracking 4 people...\n",
            "Processed 150 frames, tracking 4 people...\n",
            "Processed 180 frames, tracking 4 people...\n",
            "Processed 210 frames, tracking 4 people...\n",
            "Processed 240 frames, tracking 4 people...\n",
            "Processed 270 frames, tracking 4 people...\n",
            "Processed 300 frames, tracking 4 people...\n",
            "Processed 330 frames, tracking 4 people...\n",
            "Processed 360 frames, tracking 4 people...\n",
            "Processed 390 frames, tracking 4 people...\n",
            "Processed 420 frames, tracking 4 people...\n",
            "Processed 450 frames, tracking 4 people...\n",
            "Processed 480 frames, tracking 4 people...\n",
            "Processed 510 frames, tracking 4 people...\n",
            "Processed 540 frames, tracking 4 people...\n",
            "Processed 570 frames, tracking 4 people...\n",
            "Processed 600 frames, tracking 4 people...\n",
            "Processed 630 frames, tracking 4 people...\n",
            "Processed 660 frames, tracking 4 people...\n",
            "Processed 690 frames, tracking 5 people...\n",
            "Processed 720 frames, tracking 5 people...\n",
            "Processed 750 frames, tracking 7 people...\n",
            "Processed 780 frames, tracking 10 people...\n",
            "Processed 810 frames, tracking 10 people...\n",
            "Processed 840 frames, tracking 10 people...\n",
            "Processed 870 frames, tracking 10 people...\n",
            "Processed 900 frames, tracking 10 people...\n",
            "Processed 930 frames, tracking 10 people...\n",
            "Processed 960 frames, tracking 10 people...\n",
            "Processed 990 frames, tracking 10 people...\n",
            "Processed 1020 frames, tracking 10 people...\n",
            "Processed 1050 frames, tracking 10 people...\n",
            "Processed 1080 frames, tracking 10 people...\n",
            "Processed 1110 frames, tracking 10 people...\n",
            "Processed 1140 frames, tracking 10 people...\n",
            "Processed 1170 frames, tracking 10 people...\n",
            "Processed 1200 frames, tracking 10 people...\n",
            "Processed 1230 frames, tracking 10 people...\n",
            "Processed 1260 frames, tracking 10 people...\n",
            "Processed 1290 frames, tracking 10 people...\n",
            "Processed 1320 frames, tracking 10 people...\n",
            "Processed 1350 frames, tracking 10 people...\n",
            "Processed 1380 frames, tracking 10 people...\n",
            "Processed 1410 frames, tracking 10 people...\n",
            "Processed 1440 frames, tracking 10 people...\n",
            "Processed 1470 frames, tracking 10 people...\n",
            "Processed 1500 frames, tracking 10 people...\n",
            "Processed 1530 frames, tracking 10 people...\n",
            "Processed 1560 frames, tracking 10 people...\n",
            "Processed 1590 frames, tracking 10 people...\n",
            "Processed 1620 frames, tracking 10 people...\n",
            "Processed 1650 frames, tracking 10 people...\n",
            "Processed 1680 frames, tracking 10 people...\n",
            "Processed 1710 frames, tracking 10 people...\n",
            "Processed 1740 frames, tracking 10 people...\n",
            "Processed 1770 frames, tracking 10 people...\n",
            "Processed 1800 frames, tracking 10 people...\n",
            "Processed 1830 frames, tracking 10 people...\n",
            "Processed 1860 frames, tracking 10 people...\n",
            "Processed 1890 frames, tracking 10 people...\n",
            "Processed 1920 frames, tracking 10 people...\n",
            "Processed 1950 frames, tracking 10 people...\n",
            "Processed 1980 frames, tracking 10 people...\n",
            "Processed 2010 frames, tracking 10 people...\n",
            "Processed 2040 frames, tracking 10 people...\n",
            "Processed 2070 frames, tracking 10 people...\n",
            "\n",
            "Processing complete!\n",
            "Output saved to: tracked_multiperson_dance.mp4\n",
            "Total people tracked: 10\n",
            "Movement data saved to: multiperson_movement_data.json\n",
            "\n",
            "=== Multi-Person Movement Analysis ===\n",
            "Total people tracked: 10\n",
            "\n",
            "--- Person 0 ---\n",
            "Frames tracked: 1352\n",
            "Average movement: 0.7687\n",
            "Peak movement: 18.9885\n",
            "Total activity time: 45.07s\n",
            "Most active at: 53.10s\n",
            "\n",
            "--- Person 1 ---\n",
            "Frames tracked: 268\n",
            "Average movement: 2.1831\n",
            "Peak movement: 27.8882\n",
            "Total activity time: 8.93s\n",
            "Most active at: 53.27s\n",
            "\n",
            "--- Person 2 ---\n",
            "Frames tracked: 107\n",
            "Average movement: 3.3256\n",
            "Peak movement: 26.1980\n",
            "Total activity time: 3.57s\n",
            "Most active at: 53.33s\n",
            "\n",
            "--- Person 3 ---\n",
            "Frames tracked: 52\n",
            "Average movement: 3.7609\n",
            "Peak movement: 32.1634\n",
            "Total activity time: 1.73s\n",
            "Most active at: 39.43s\n",
            "\n",
            "--- Person 4 ---\n",
            "Frames tracked: 119\n",
            "Average movement: 1.8124\n",
            "Peak movement: 21.2037\n",
            "Total activity time: 3.97s\n",
            "Most active at: 68.90s\n",
            "\n",
            "--- Person 5 ---\n",
            "Frames tracked: 18\n",
            "Average movement: 4.0024\n",
            "Peak movement: 13.6250\n",
            "Total activity time: 0.60s\n",
            "Most active at: 53.63s\n",
            "\n",
            "--- Person 6 ---\n",
            "Frames tracked: 12\n",
            "Average movement: 5.4471\n",
            "Peak movement: 17.5145\n",
            "Total activity time: 0.40s\n",
            "Most active at: 39.57s\n",
            "\n",
            "--- Person 7 ---\n",
            "Frames tracked: 23\n",
            "Average movement: 3.0639\n",
            "Peak movement: 15.7322\n",
            "Total activity time: 0.77s\n",
            "Most active at: 39.67s\n",
            "\n",
            "--- Person 8 ---\n",
            "Frames tracked: 27\n",
            "Average movement: 2.6501\n",
            "Peak movement: 11.2900\n",
            "Total activity time: 0.90s\n",
            "Most active at: 39.83s\n",
            "\n",
            "--- Person 9 ---\n",
            "Frames tracked: 17\n",
            "Average movement: 2.2094\n",
            "Peak movement: 4.0997\n",
            "Total activity time: 0.57s\n",
            "Most active at: 46.33s\n",
            "\n",
            "=== Dancer Comparison ===\n",
            "Ranking by average movement intensity:\n",
            "  1. Person 6: 5.4471\n",
            "  2. Person 5: 4.0024\n",
            "  3. Person 3: 3.7609\n",
            "  4. Person 2: 3.3256\n",
            "  5. Person 7: 3.0639\n",
            "  6. Person 8: 2.6501\n",
            "  7. Person 9: 2.2094\n",
            "  8. Person 1: 2.1831\n",
            "  9. Person 4: 1.8124\n",
            "  10. Person 0: 0.7687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vbnYdejHPLzd",
        "outputId": "aa53ed47-2fca-40b3-c81b-a16bc8872f43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.218-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Collecting numpy>=1.23.0 (from ultralytics)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.218-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: numpy, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.6 ultralytics-8.3.218 ultralytics-thop-2.0.17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "81edfc12c327409692e6baf7422022a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "class YOLODanceTracker:\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = video_path\n",
        "\n",
        "        # Validate video file first\n",
        "        if not self.validate_video():\n",
        "            raise ValueError(\"Invalid or corrupted video file!\")\n",
        "\n",
        "        # Initialize YOLO for person detection\n",
        "        print(\"Loading YOLO model...\")\n",
        "        self.yolo_model = YOLO('yolov8n.pt')\n",
        "\n",
        "        # Initialize MediaPipe for detailed pose estimation\n",
        "        print(\"Loading MediaPipe pose model...\")\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            static_image_mode=False,\n",
        "            model_complexity=1,\n",
        "            min_detection_confidence=0.6,\n",
        "            min_tracking_confidence=0.6\n",
        "        )\n",
        "\n",
        "        self.movement_data = defaultdict(list)\n",
        "        self.person_colors = {}\n",
        "        self.prev_landmarks = {}\n",
        "\n",
        "    def validate_video(self):\n",
        "        \"\"\"Validate video file before processing\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"VIDEO VALIDATION\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(self.video_path):\n",
        "            print(f\"❌ ERROR: File not found: {self.video_path}\")\n",
        "            return False\n",
        "\n",
        "        # Check file size\n",
        "        file_size = os.path.getsize(self.video_path)\n",
        "        print(f\"File size: {file_size:,} bytes ({file_size / 1024:.2f} KB)\")\n",
        "\n",
        "        if file_size < 10000:  # Less than 10KB is suspicious\n",
        "            print(\"❌ ERROR: File is too small (likely corrupted or empty)\")\n",
        "            print(\"\\nPossible issues:\")\n",
        "            print(\"  - Incomplete download\")\n",
        "            print(\"  - Corrupted file\")\n",
        "            print(\"  - Wrong file path\")\n",
        "            print(\"  - File is just metadata without video data\")\n",
        "            return False\n",
        "\n",
        "        # Try to open video\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(\"❌ ERROR: Cannot open video file\")\n",
        "            print(\"\\nPossible issues:\")\n",
        "            print(\"  - Unsupported codec\")\n",
        "            print(\"  - Corrupted file structure\")\n",
        "            print(\"  - Missing codecs on system\")\n",
        "            cap.release()\n",
        "            return False\n",
        "\n",
        "        # Get video properties\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "        print(f\"\\n✓ Video Properties:\")\n",
        "        print(f\"  Resolution: {width}x{height}\")\n",
        "        print(f\"  FPS: {fps}\")\n",
        "        print(f\"  Total frames: {frame_count}\")\n",
        "        print(f\"  Duration: {duration:.2f} seconds\")\n",
        "\n",
        "        # Try to read first frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame is None:\n",
        "            print(\"\\n❌ ERROR: Cannot read video frames\")\n",
        "            print(\"The file exists but contains no readable video data\")\n",
        "            cap.release()\n",
        "            return False\n",
        "\n",
        "        print(f\"  First frame shape: {frame.shape}\")\n",
        "        print(\"\\n✓ Video file is valid!\")\n",
        "        cap.release()\n",
        "        return True\n",
        "\n",
        "    def generate_color(self, person_id):\n",
        "        \"\"\"Generate unique color for each person\"\"\"\n",
        "        if person_id not in self.person_colors:\n",
        "            np.random.seed(person_id * 42)\n",
        "            self.person_colors[person_id] = tuple(np.random.randint(50, 255, 3).tolist())\n",
        "        return self.person_colors[person_id]\n",
        "\n",
        "    def calculate_velocity(self, prev_landmarks, curr_landmarks):\n",
        "        \"\"\"Calculate movement velocity between frames\"\"\"\n",
        "        if prev_landmarks is None:\n",
        "            return 0\n",
        "\n",
        "        total_movement = 0\n",
        "        for i in range(min(len(prev_landmarks), len(curr_landmarks))):\n",
        "            prev = np.array([prev_landmarks[i].x, prev_landmarks[i].y])\n",
        "            curr = np.array([curr_landmarks[i].x, curr_landmarks[i].y])\n",
        "            total_movement += np.linalg.norm(curr - prev)\n",
        "\n",
        "        return total_movement\n",
        "\n",
        "    def get_joint_angles(self, landmarks):\n",
        "        \"\"\"Calculate key joint angles\"\"\"\n",
        "        def angle_between(p1, p2, p3):\n",
        "            v1 = np.array([p1.x - p2.x, p1.y - p2.y])\n",
        "            v2 = np.array([p3.x - p2.x, p3.y - p2.y])\n",
        "\n",
        "            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
        "            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
        "            return np.degrees(angle)\n",
        "\n",
        "        angles = {}\n",
        "        try:\n",
        "            angles['right_elbow'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
        "            )\n",
        "            angles['left_elbow'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
        "            )\n",
        "            angles['right_knee'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
        "            )\n",
        "            angles['left_knee'] = angle_between(\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "                landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
        "            )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return angles\n",
        "\n",
        "    def calculate_energy_level(self, velocity, angles):\n",
        "        \"\"\"Calculate overall energy/intensity level\"\"\"\n",
        "        energy = velocity * 10\n",
        "\n",
        "        if angles:\n",
        "            for angle in angles.values():\n",
        "                if 30 < angle < 150:\n",
        "                    energy += 0.5\n",
        "\n",
        "        return energy\n",
        "\n",
        "    def process_video(self, output_path='output_yolo_dance.mp4', save_data=True,\n",
        "                     min_detection_confidence=0.7, max_people=50):\n",
        "        \"\"\"Process video with YOLO detection + MediaPipe pose\"\"\"\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height + 60))\n",
        "\n",
        "        frame_count = 0\n",
        "        frame_skip = 0  # Process every frame\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"PROCESSING VIDEO\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Video: {total_frames} frames at {fps} FPS\")\n",
        "        print(f\"Resolution: {width}x{height}\")\n",
        "        print(f\"Min confidence: {min_detection_confidence}\")\n",
        "        print(f\"Max people to track: {max_people}\")\n",
        "        print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Skip frames for faster processing (optional)\n",
        "            if frame_count % (frame_skip + 1) != 0:\n",
        "                continue\n",
        "\n",
        "            # YOLO detection with stricter settings\n",
        "            results = self.yolo_model.track(\n",
        "                frame,\n",
        "                persist=True,\n",
        "                classes=[0],  # Only detect persons\n",
        "                conf=min_detection_confidence,\n",
        "                iou=0.5,\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "            current_detections = []\n",
        "\n",
        "            if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
        "                boxes = results[0].boxes\n",
        "\n",
        "                # Limit number of tracked people\n",
        "                if len(boxes) > max_people:\n",
        "                    print(f\"⚠️  Warning: {len(boxes)} people detected in frame {frame_count}, \"\n",
        "                          f\"limiting to {max_people}\")\n",
        "                    boxes = boxes[:max_people]\n",
        "\n",
        "                for i, box in enumerate(boxes):\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    confidence = float(box.conf[0])\n",
        "\n",
        "                    # Get tracking ID\n",
        "                    track_id = int(box.id[0]) if box.id is not None else None\n",
        "\n",
        "                    if track_id is None or confidence < min_detection_confidence:\n",
        "                        continue\n",
        "\n",
        "                    # Validate bounding box size (filter out tiny detections)\n",
        "                    box_width = x2 - x1\n",
        "                    box_height = y2 - y1\n",
        "\n",
        "                    if box_width < 30 or box_height < 50:  # Too small\n",
        "                        continue\n",
        "\n",
        "                    if box_width > width * 0.8 or box_height > height * 0.8:  # Too large\n",
        "                        continue\n",
        "\n",
        "                    # Crop person from frame\n",
        "                    person_crop = frame[max(0, y1):min(height, y2),\n",
        "                                       max(0, x1):min(width, x2)]\n",
        "\n",
        "                    if person_crop.size == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Run pose estimation\n",
        "                    rgb_crop = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "                    pose_results = self.pose.process(rgb_crop)\n",
        "\n",
        "                    if pose_results.pose_landmarks:\n",
        "                        landmarks = pose_results.pose_landmarks.landmark\n",
        "\n",
        "                        velocity = self.calculate_velocity(\n",
        "                            self.prev_landmarks.get(track_id),\n",
        "                            landmarks\n",
        "                        )\n",
        "\n",
        "                        angles = self.get_joint_angles(landmarks)\n",
        "                        energy = self.calculate_energy_level(velocity, angles)\n",
        "\n",
        "                        # Store data\n",
        "                        frame_data = {\n",
        "                            'frame': frame_count,\n",
        "                            'person_id': track_id,\n",
        "                            'velocity': float(velocity),\n",
        "                            'energy': float(energy),\n",
        "                            'angles': angles,\n",
        "                            'bbox': {'x': x1, 'y': y1, 'w': box_width, 'h': box_height},\n",
        "                            'confidence': float(confidence),\n",
        "                            'timestamp': frame_count / fps\n",
        "                        }\n",
        "                        self.movement_data[track_id].append(frame_data)\n",
        "\n",
        "                        color = self.generate_color(track_id)\n",
        "\n",
        "                        # Draw skeleton\n",
        "                        for landmark in landmarks:\n",
        "                            lx = int(landmark.x * box_width + x1)\n",
        "                            ly = int(landmark.y * box_height + y1)\n",
        "                            cv2.circle(frame, (lx, ly), 3, color, -1)\n",
        "\n",
        "                        # Draw connections\n",
        "                        for connection in self.mp_pose.POSE_CONNECTIONS:\n",
        "                            start = landmarks[connection[0]]\n",
        "                            end = landmarks[connection[1]]\n",
        "\n",
        "                            start_x = int(start.x * box_width + x1)\n",
        "                            start_y = int(start.y * box_height + y1)\n",
        "                            end_x = int(end.x * box_width + x1)\n",
        "                            end_y = int(end.y * box_height + y1)\n",
        "\n",
        "                            cv2.line(frame, (start_x, start_y), (end_x, end_y),\n",
        "                                   color, 2)\n",
        "\n",
        "                        # Draw bounding box and labels\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                        cv2.putText(frame, f'ID:{track_id}', (x1, y1 - 10),\n",
        "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "                        cv2.putText(frame, f'E:{energy:.1f}', (x1, y2 + 20),\n",
        "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                        self.prev_landmarks[track_id] = landmarks\n",
        "                        current_detections.append(track_id)\n",
        "\n",
        "            # Add info bar\n",
        "            info_bg = np.zeros((60, width, 3), dtype=np.uint8)\n",
        "            cv2.putText(info_bg, f'Frame: {frame_count}/{total_frames}',\n",
        "                       (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "            cv2.putText(info_bg, f'Current: {len(current_detections)} | Total: {len(self.movement_data)}',\n",
        "                       (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "            frame_with_info = np.vstack([info_bg, frame])\n",
        "            out.write(frame_with_info)\n",
        "\n",
        "            if frame_count % 30 == 0:\n",
        "                progress = (frame_count / total_frames) * 100\n",
        "                print(f\"Progress: {progress:.1f}% | Frame {frame_count}/{total_frames} | \"\n",
        "                      f\"Current: {len(current_detections)} dancers | \"\n",
        "                      f\"Total tracked: {len(self.movement_data)}\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(f\"✓ Processing complete!\")\n",
        "        print(f\"✓ Output: {output_path}\")\n",
        "        print(f\"✓ Unique dancers: {len(self.movement_data)}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        if save_data:\n",
        "            data_file = 'yolo_dance_data.json'\n",
        "            with open(data_file, 'w') as f:\n",
        "                json.dump(dict(self.movement_data), f, indent=2)\n",
        "            print(f\"✓ Data saved: {data_file}\")\n",
        "\n",
        "        if len(self.movement_data) > 0:\n",
        "            self.analyze_movements()\n",
        "            self.generate_summary()\n",
        "        else:\n",
        "            print(\"\\n⚠️  WARNING: No dancers detected in video!\")\n",
        "            print(\"Possible issues:\")\n",
        "            print(\"  - Video quality too low\")\n",
        "            print(\"  - No people visible in frames\")\n",
        "            print(\"  - Detection confidence threshold too high\")\n",
        "\n",
        "    def analyze_movements(self):\n",
        "        \"\"\"Analyze movement patterns\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"INDIVIDUAL DANCER ANALYSIS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for person_id, data in sorted(self.movement_data.items()):\n",
        "            velocities = [d['velocity'] for d in data]\n",
        "            energies = [d['energy'] for d in data]\n",
        "\n",
        "            print(f\"\\n--- Person {person_id} ---\")\n",
        "            print(f\"Frames: {len(data)} | Time: {len(data) / 30:.2f}s\")\n",
        "            print(f\"Avg velocity: {np.mean(velocities):.4f}\")\n",
        "            print(f\"Avg energy: {np.mean(energies):.2f}\")\n",
        "            print(f\"Peak energy: {np.max(energies):.2f}\")\n",
        "\n",
        "    def generate_summary(self):\n",
        "        \"\"\"Generate comparative summary\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"COMPARATIVE ANALYSIS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        dancer_stats = {}\n",
        "        for pid, data in self.movement_data.items():\n",
        "            dancer_stats[pid] = {\n",
        "                'avg_energy': np.mean([d['energy'] for d in data]),\n",
        "                'screen_time': len(data) / 30,\n",
        "                'total_frames': len(data)\n",
        "            }\n",
        "\n",
        "        print(\"\\nTop 10 by Energy Level:\")\n",
        "        sorted_by_energy = sorted(dancer_stats.items(),\n",
        "                                 key=lambda x: x[1]['avg_energy'],\n",
        "                                 reverse=True)[:10]\n",
        "        for rank, (pid, stats) in enumerate(sorted_by_energy, 1):\n",
        "            print(f\"  {rank}. Person {pid}: {stats['avg_energy']:.2f} \"\n",
        "                  f\"(time: {stats['screen_time']:.1f}s)\")\n",
        "\n",
        "        print(\"\\nTop 10 by Screen Time:\")\n",
        "        sorted_by_time = sorted(dancer_stats.items(),\n",
        "                               key=lambda x: x[1]['screen_time'],\n",
        "                               reverse=True)[:10]\n",
        "        for rank, (pid, stats) in enumerate(sorted_by_time, 1):\n",
        "            print(f\"  {rank}. Person {pid}: {stats['screen_time']:.1f}s \"\n",
        "                  f\"({stats['total_frames']} frames)\")\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        tracker = YOLODanceTracker('dance.mp4')\n",
        "\n",
        "        # Process with stricter settings to avoid false detections\n",
        "        tracker.process_video(\n",
        "            output_path='yolo_tracked_dance.mp4',\n",
        "            save_data=True,\n",
        "            min_detection_confidence=0.7,  # Higher confidence\n",
        "            max_people=50  # Reasonable limit\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting steps:\")\n",
        "        print(\"1. Check if dance.mp4 exists and is not corrupted\")\n",
        "        print(\"2. Try re-downloading or re-encoding the video\")\n",
        "        print(\"3. Test with a different video file\")\n",
        "        print(\"4. Verify video with: ffmpeg -i dance.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9CK7PD-ShqL",
        "outputId": "60ab1adc-0c6c-4e18-f54b-1e407be2c135"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "VIDEO VALIDATION\n",
            "==================================================\n",
            "File size: 57,286,555 bytes (55943.90 KB)\n",
            "\n",
            "✓ Video Properties:\n",
            "  Resolution: 1914x800\n",
            "  FPS: 30\n",
            "  Total frames: 2078\n",
            "  Duration: 69.27 seconds\n",
            "  First frame shape: (800, 1914, 3)\n",
            "\n",
            "✓ Video file is valid!\n",
            "Loading YOLO model...\n",
            "Loading MediaPipe pose model...\n",
            "\n",
            "==================================================\n",
            "PROCESSING VIDEO\n",
            "==================================================\n",
            "Video: 2078 frames at 30 FPS\n",
            "Resolution: 1914x800\n",
            "Min confidence: 0.7\n",
            "Max people to track: 50\n",
            "==================================================\n",
            "\n",
            "Progress: 1.4% | Frame 30/2078 | Current: 0 dancers | Total tracked: 2\n",
            "Progress: 2.9% | Frame 60/2078 | Current: 0 dancers | Total tracked: 2\n",
            "Progress: 4.3% | Frame 90/2078 | Current: 1 dancers | Total tracked: 2\n",
            "Progress: 5.8% | Frame 120/2078 | Current: 1 dancers | Total tracked: 3\n",
            "Progress: 7.2% | Frame 150/2078 | Current: 0 dancers | Total tracked: 3\n",
            "Progress: 8.7% | Frame 180/2078 | Current: 0 dancers | Total tracked: 3\n",
            "Progress: 10.1% | Frame 210/2078 | Current: 1 dancers | Total tracked: 6\n",
            "Progress: 11.5% | Frame 240/2078 | Current: 2 dancers | Total tracked: 9\n",
            "Progress: 13.0% | Frame 270/2078 | Current: 2 dancers | Total tracked: 10\n",
            "Progress: 14.4% | Frame 300/2078 | Current: 0 dancers | Total tracked: 11\n",
            "Progress: 15.9% | Frame 330/2078 | Current: 1 dancers | Total tracked: 13\n",
            "Progress: 17.3% | Frame 360/2078 | Current: 3 dancers | Total tracked: 16\n",
            "Progress: 18.8% | Frame 390/2078 | Current: 1 dancers | Total tracked: 17\n",
            "Progress: 20.2% | Frame 420/2078 | Current: 2 dancers | Total tracked: 18\n",
            "Progress: 21.7% | Frame 450/2078 | Current: 2 dancers | Total tracked: 18\n",
            "Progress: 23.1% | Frame 480/2078 | Current: 3 dancers | Total tracked: 21\n",
            "Progress: 24.5% | Frame 510/2078 | Current: 0 dancers | Total tracked: 22\n",
            "Progress: 26.0% | Frame 540/2078 | Current: 1 dancers | Total tracked: 24\n",
            "Progress: 27.4% | Frame 570/2078 | Current: 0 dancers | Total tracked: 27\n",
            "Progress: 28.9% | Frame 600/2078 | Current: 3 dancers | Total tracked: 33\n",
            "Progress: 30.3% | Frame 630/2078 | Current: 2 dancers | Total tracked: 33\n",
            "Progress: 31.8% | Frame 660/2078 | Current: 0 dancers | Total tracked: 36\n",
            "Progress: 33.2% | Frame 690/2078 | Current: 1 dancers | Total tracked: 38\n",
            "Progress: 34.6% | Frame 720/2078 | Current: 2 dancers | Total tracked: 41\n",
            "Progress: 36.1% | Frame 750/2078 | Current: 1 dancers | Total tracked: 46\n",
            "Progress: 37.5% | Frame 780/2078 | Current: 2 dancers | Total tracked: 51\n",
            "Progress: 39.0% | Frame 810/2078 | Current: 3 dancers | Total tracked: 51\n",
            "Progress: 40.4% | Frame 840/2078 | Current: 3 dancers | Total tracked: 54\n",
            "Progress: 41.9% | Frame 870/2078 | Current: 1 dancers | Total tracked: 55\n",
            "Progress: 43.3% | Frame 900/2078 | Current: 4 dancers | Total tracked: 59\n",
            "Progress: 44.8% | Frame 930/2078 | Current: 2 dancers | Total tracked: 59\n",
            "Progress: 46.2% | Frame 960/2078 | Current: 2 dancers | Total tracked: 62\n",
            "Progress: 47.6% | Frame 990/2078 | Current: 1 dancers | Total tracked: 62\n",
            "Progress: 49.1% | Frame 1020/2078 | Current: 3 dancers | Total tracked: 65\n",
            "Progress: 50.5% | Frame 1050/2078 | Current: 2 dancers | Total tracked: 66\n",
            "Progress: 52.0% | Frame 1080/2078 | Current: 0 dancers | Total tracked: 67\n",
            "Progress: 53.4% | Frame 1110/2078 | Current: 3 dancers | Total tracked: 71\n",
            "Progress: 54.9% | Frame 1140/2078 | Current: 2 dancers | Total tracked: 71\n",
            "Progress: 56.3% | Frame 1170/2078 | Current: 1 dancers | Total tracked: 74\n",
            "Progress: 57.7% | Frame 1200/2078 | Current: 3 dancers | Total tracked: 78\n",
            "Progress: 59.2% | Frame 1230/2078 | Current: 1 dancers | Total tracked: 78\n",
            "Progress: 60.6% | Frame 1260/2078 | Current: 2 dancers | Total tracked: 81\n",
            "Progress: 62.1% | Frame 1290/2078 | Current: 2 dancers | Total tracked: 83\n",
            "Progress: 63.5% | Frame 1320/2078 | Current: 2 dancers | Total tracked: 84\n",
            "Progress: 65.0% | Frame 1350/2078 | Current: 0 dancers | Total tracked: 87\n",
            "Progress: 66.4% | Frame 1380/2078 | Current: 3 dancers | Total tracked: 88\n",
            "Progress: 67.9% | Frame 1410/2078 | Current: 1 dancers | Total tracked: 89\n",
            "Progress: 69.3% | Frame 1440/2078 | Current: 2 dancers | Total tracked: 92\n",
            "Progress: 70.7% | Frame 1470/2078 | Current: 1 dancers | Total tracked: 94\n",
            "Progress: 72.2% | Frame 1500/2078 | Current: 0 dancers | Total tracked: 95\n",
            "Progress: 73.6% | Frame 1530/2078 | Current: 2 dancers | Total tracked: 97\n",
            "Progress: 75.1% | Frame 1560/2078 | Current: 1 dancers | Total tracked: 97\n",
            "Progress: 76.5% | Frame 1590/2078 | Current: 0 dancers | Total tracked: 97\n",
            "Progress: 78.0% | Frame 1620/2078 | Current: 3 dancers | Total tracked: 102\n",
            "Progress: 79.4% | Frame 1650/2078 | Current: 3 dancers | Total tracked: 102\n",
            "Progress: 80.8% | Frame 1680/2078 | Current: 2 dancers | Total tracked: 104\n",
            "Progress: 82.3% | Frame 1710/2078 | Current: 0 dancers | Total tracked: 105\n",
            "Progress: 83.7% | Frame 1740/2078 | Current: 0 dancers | Total tracked: 105\n",
            "Progress: 85.2% | Frame 1770/2078 | Current: 2 dancers | Total tracked: 107\n",
            "Progress: 86.6% | Frame 1800/2078 | Current: 2 dancers | Total tracked: 109\n",
            "Progress: 88.1% | Frame 1830/2078 | Current: 0 dancers | Total tracked: 110\n",
            "Progress: 89.5% | Frame 1860/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 91.0% | Frame 1890/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 92.4% | Frame 1920/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 93.8% | Frame 1950/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 95.3% | Frame 1980/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 96.7% | Frame 2010/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 98.2% | Frame 2040/2078 | Current: 0 dancers | Total tracked: 111\n",
            "Progress: 99.6% | Frame 2070/2078 | Current: 2 dancers | Total tracked: 115\n",
            "\n",
            "==================================================\n",
            "✓ Processing complete!\n",
            "✓ Output: yolo_tracked_dance.mp4\n",
            "✓ Unique dancers: 115\n",
            "==================================================\n",
            "✓ Data saved: yolo_dance_data.json\n",
            "\n",
            "==================================================\n",
            "INDIVIDUAL DANCER ANALYSIS\n",
            "==================================================\n",
            "\n",
            "--- Person 1 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 4.0944\n",
            "Avg energy: 42.34\n",
            "Peak energy: 153.12\n",
            "\n",
            "--- Person 3 ---\n",
            "Frames: 74 | Time: 2.47s\n",
            "Avg velocity: 2.1275\n",
            "Avg energy: 22.37\n",
            "Peak energy: 189.45\n",
            "\n",
            "--- Person 4 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 2.1299\n",
            "Avg energy: 21.50\n",
            "Peak energy: 43.24\n",
            "\n",
            "--- Person 5 ---\n",
            "Frames: 33 | Time: 1.10s\n",
            "Avg velocity: 4.9738\n",
            "Avg energy: 50.87\n",
            "Peak energy: 326.94\n",
            "\n",
            "--- Person 6 ---\n",
            "Frames: 34 | Time: 1.13s\n",
            "Avg velocity: 116.0070\n",
            "Avg energy: 1161.10\n",
            "Peak energy: 10911.67\n",
            "\n",
            "--- Person 7 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 2.2298\n",
            "Avg energy: 24.30\n",
            "Peak energy: 46.60\n",
            "\n",
            "--- Person 8 ---\n",
            "Frames: 6 | Time: 0.20s\n",
            "Avg velocity: 18.9173\n",
            "Avg energy: 190.42\n",
            "Peak energy: 476.00\n",
            "\n",
            "--- Person 9 ---\n",
            "Frames: 58 | Time: 1.93s\n",
            "Avg velocity: 74.7569\n",
            "Avg energy: 748.97\n",
            "Peak energy: 9968.74\n",
            "\n",
            "--- Person 10 ---\n",
            "Frames: 6 | Time: 0.20s\n",
            "Avg velocity: 138.5043\n",
            "Avg energy: 1385.88\n",
            "Peak energy: 7883.01\n",
            "\n",
            "--- Person 11 ---\n",
            "Frames: 10 | Time: 0.33s\n",
            "Avg velocity: 77.0208\n",
            "Avg energy: 771.26\n",
            "Peak energy: 2973.68\n",
            "\n",
            "--- Person 12 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 10.5171\n",
            "Avg energy: 106.21\n",
            "Peak energy: 526.20\n",
            "\n",
            "--- Person 13 ---\n",
            "Frames: 7 | Time: 0.23s\n",
            "Avg velocity: 9.2499\n",
            "Avg energy: 93.64\n",
            "Peak energy: 247.11\n",
            "\n",
            "--- Person 15 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 17.5953\n",
            "Avg energy: 177.33\n",
            "Peak energy: 341.26\n",
            "\n",
            "--- Person 18 ---\n",
            "Frames: 10 | Time: 0.33s\n",
            "Avg velocity: 13.6762\n",
            "Avg energy: 138.01\n",
            "Peak energy: 380.31\n",
            "\n",
            "--- Person 19 ---\n",
            "Frames: 87 | Time: 2.90s\n",
            "Avg velocity: 3.7435\n",
            "Avg energy: 38.26\n",
            "Peak energy: 657.89\n",
            "\n",
            "--- Person 20 ---\n",
            "Frames: 22 | Time: 0.73s\n",
            "Avg velocity: 5.9756\n",
            "Avg energy: 60.32\n",
            "Peak energy: 328.48\n",
            "\n",
            "--- Person 21 ---\n",
            "Frames: 38 | Time: 1.27s\n",
            "Avg velocity: 0.8536\n",
            "Avg energy: 8.73\n",
            "Peak energy: 54.60\n",
            "\n",
            "--- Person 22 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 2.5755\n",
            "Avg energy: 26.45\n",
            "Peak energy: 48.07\n",
            "\n",
            "--- Person 23 ---\n",
            "Frames: 45 | Time: 1.50s\n",
            "Avg velocity: 2.4355\n",
            "Avg energy: 25.98\n",
            "Peak energy: 103.64\n",
            "\n",
            "--- Person 24 ---\n",
            "Frames: 33 | Time: 1.10s\n",
            "Avg velocity: 5.2167\n",
            "Avg energy: 53.23\n",
            "Peak energy: 247.95\n",
            "\n",
            "--- Person 25 ---\n",
            "Frames: 31 | Time: 1.03s\n",
            "Avg velocity: 5.2733\n",
            "Avg energy: 54.07\n",
            "Peak energy: 143.10\n",
            "\n",
            "--- Person 26 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 1.6384\n",
            "Avg energy: 17.38\n",
            "Peak energy: 32.06\n",
            "\n",
            "--- Person 28 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 0.00\n",
            "Peak energy: 0.00\n",
            "\n",
            "--- Person 29 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 25.8069\n",
            "Avg energy: 259.17\n",
            "Peak energy: 562.19\n",
            "\n",
            "--- Person 31 ---\n",
            "Frames: 9 | Time: 0.30s\n",
            "Avg velocity: 34.2142\n",
            "Avg energy: 343.20\n",
            "Peak energy: 908.58\n",
            "\n",
            "--- Person 33 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 27.8028\n",
            "Avg energy: 279.32\n",
            "Peak energy: 1244.52\n",
            "\n",
            "--- Person 34 ---\n",
            "Frames: 10 | Time: 0.33s\n",
            "Avg velocity: 26.1863\n",
            "Avg energy: 262.81\n",
            "Peak energy: 671.54\n",
            "\n",
            "--- Person 35 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 1.50\n",
            "Peak energy: 1.50\n",
            "\n",
            "--- Person 36 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 27.9764\n",
            "Avg energy: 281.06\n",
            "Peak energy: 730.29\n",
            "\n",
            "--- Person 37 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 37.2955\n",
            "Avg energy: 374.71\n",
            "Peak energy: 747.91\n",
            "\n",
            "--- Person 38 ---\n",
            "Frames: 35 | Time: 1.17s\n",
            "Avg velocity: 3.6018\n",
            "Avg energy: 37.72\n",
            "Peak energy: 884.78\n",
            "\n",
            "--- Person 39 ---\n",
            "Frames: 83 | Time: 2.77s\n",
            "Avg velocity: 4.8047\n",
            "Avg energy: 49.03\n",
            "Peak energy: 1279.56\n",
            "\n",
            "--- Person 40 ---\n",
            "Frames: 19 | Time: 0.63s\n",
            "Avg velocity: 3.8409\n",
            "Avg energy: 39.30\n",
            "Peak energy: 113.01\n",
            "\n",
            "--- Person 42 ---\n",
            "Frames: 16 | Time: 0.53s\n",
            "Avg velocity: 8.1649\n",
            "Avg energy: 83.24\n",
            "Peak energy: 275.78\n",
            "\n",
            "--- Person 43 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 5.8321\n",
            "Avg energy: 59.45\n",
            "Peak energy: 86.27\n",
            "\n",
            "--- Person 44 ---\n",
            "Frames: 9 | Time: 0.30s\n",
            "Avg velocity: 12.6098\n",
            "Avg energy: 127.49\n",
            "Peak energy: 242.86\n",
            "\n",
            "--- Person 45 ---\n",
            "Frames: 23 | Time: 0.77s\n",
            "Avg velocity: 5.6756\n",
            "Avg energy: 58.28\n",
            "Peak energy: 396.74\n",
            "\n",
            "--- Person 47 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 1.3188\n",
            "Avg energy: 13.69\n",
            "Peak energy: 27.11\n",
            "\n",
            "--- Person 48 ---\n",
            "Frames: 5 | Time: 0.17s\n",
            "Avg velocity: 3.0874\n",
            "Avg energy: 32.57\n",
            "Peak energy: 58.29\n",
            "\n",
            "--- Person 49 ---\n",
            "Frames: 55 | Time: 1.83s\n",
            "Avg velocity: 3.1081\n",
            "Avg energy: 32.55\n",
            "Peak energy: 233.47\n",
            "\n",
            "--- Person 52 ---\n",
            "Frames: 21 | Time: 0.70s\n",
            "Avg velocity: 2.4260\n",
            "Avg energy: 25.43\n",
            "Peak energy: 63.61\n",
            "\n",
            "--- Person 54 ---\n",
            "Frames: 13 | Time: 0.43s\n",
            "Avg velocity: 3.5564\n",
            "Avg energy: 37.10\n",
            "Peak energy: 137.16\n",
            "\n",
            "--- Person 55 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 1.00\n",
            "Peak energy: 1.00\n",
            "\n",
            "--- Person 56 ---\n",
            "Frames: 21 | Time: 0.70s\n",
            "Avg velocity: 5.7163\n",
            "Avg energy: 58.02\n",
            "Peak energy: 171.78\n",
            "\n",
            "--- Person 57 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 3.6239\n",
            "Avg energy: 36.74\n",
            "Peak energy: 72.98\n",
            "\n",
            "--- Person 58 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 10.3809\n",
            "Avg energy: 104.43\n",
            "Peak energy: 250.73\n",
            "\n",
            "--- Person 59 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 1.50\n",
            "Peak energy: 1.50\n",
            "\n",
            "--- Person 60 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 2.1129\n",
            "Avg energy: 22.63\n",
            "Peak energy: 43.76\n",
            "\n",
            "--- Person 61 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 1.50\n",
            "Peak energy: 1.50\n",
            "\n",
            "--- Person 62 ---\n",
            "Frames: 59 | Time: 1.97s\n",
            "Avg velocity: 19.7619\n",
            "Avg energy: 199.02\n",
            "Peak energy: 1715.40\n",
            "\n",
            "--- Person 63 ---\n",
            "Frames: 46 | Time: 1.53s\n",
            "Avg velocity: 2.5176\n",
            "Avg energy: 25.51\n",
            "Peak energy: 136.43\n",
            "\n",
            "--- Person 64 ---\n",
            "Frames: 27 | Time: 0.90s\n",
            "Avg velocity: 12.7897\n",
            "Avg energy: 128.93\n",
            "Peak energy: 519.73\n",
            "\n",
            "--- Person 65 ---\n",
            "Frames: 14 | Time: 0.47s\n",
            "Avg velocity: 24.4597\n",
            "Avg energy: 245.28\n",
            "Peak energy: 620.42\n",
            "\n",
            "--- Person 66 ---\n",
            "Frames: 28 | Time: 0.93s\n",
            "Avg velocity: 17.6479\n",
            "Avg energy: 177.46\n",
            "Peak energy: 644.05\n",
            "\n",
            "--- Person 67 ---\n",
            "Frames: 101 | Time: 3.37s\n",
            "Avg velocity: 9.0664\n",
            "Avg energy: 91.68\n",
            "Peak energy: 1321.40\n",
            "\n",
            "--- Person 69 ---\n",
            "Frames: 40 | Time: 1.33s\n",
            "Avg velocity: 4.3500\n",
            "Avg energy: 44.83\n",
            "Peak energy: 153.21\n",
            "\n",
            "--- Person 70 ---\n",
            "Frames: 8 | Time: 0.27s\n",
            "Avg velocity: 2.0517\n",
            "Avg energy: 21.58\n",
            "Peak energy: 62.87\n",
            "\n",
            "--- Person 73 ---\n",
            "Frames: 40 | Time: 1.33s\n",
            "Avg velocity: 23.6151\n",
            "Avg energy: 237.00\n",
            "Peak energy: 2808.86\n",
            "\n",
            "--- Person 74 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 16.8741\n",
            "Avg energy: 169.78\n",
            "Peak energy: 1113.28\n",
            "\n",
            "--- Person 75 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 2.00\n",
            "Peak energy: 2.00\n",
            "\n",
            "--- Person 76 ---\n",
            "Frames: 33 | Time: 1.10s\n",
            "Avg velocity: 10.6327\n",
            "Avg energy: 107.46\n",
            "Peak energy: 782.08\n",
            "\n",
            "--- Person 77 ---\n",
            "Frames: 48 | Time: 1.60s\n",
            "Avg velocity: 12.2211\n",
            "Avg energy: 123.34\n",
            "Peak energy: 412.71\n",
            "\n",
            "--- Person 78 ---\n",
            "Frames: 8 | Time: 0.27s\n",
            "Avg velocity: 2.7063\n",
            "Avg energy: 27.94\n",
            "Peak energy: 58.62\n",
            "\n",
            "--- Person 79 ---\n",
            "Frames: 61 | Time: 2.03s\n",
            "Avg velocity: 34.0445\n",
            "Avg energy: 341.68\n",
            "Peak energy: 8618.97\n",
            "\n",
            "--- Person 80 ---\n",
            "Frames: 28 | Time: 0.93s\n",
            "Avg velocity: 64.0166\n",
            "Avg energy: 641.70\n",
            "Peak energy: 8375.67\n",
            "\n",
            "--- Person 81 ---\n",
            "Frames: 31 | Time: 1.03s\n",
            "Avg velocity: 11.4351\n",
            "Avg energy: 115.43\n",
            "Peak energy: 769.45\n",
            "\n",
            "--- Person 82 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 23.1784\n",
            "Avg energy: 233.28\n",
            "Peak energy: 465.07\n",
            "\n",
            "--- Person 85 ---\n",
            "Frames: 34 | Time: 1.13s\n",
            "Avg velocity: 4.7744\n",
            "Avg energy: 49.19\n",
            "Peak energy: 348.55\n",
            "\n",
            "--- Person 86 ---\n",
            "Frames: 40 | Time: 1.33s\n",
            "Avg velocity: 3.3944\n",
            "Avg energy: 35.33\n",
            "Peak energy: 289.11\n",
            "\n",
            "--- Person 87 ---\n",
            "Frames: 29 | Time: 0.97s\n",
            "Avg velocity: 3.8174\n",
            "Avg energy: 39.55\n",
            "Peak energy: 368.81\n",
            "\n",
            "--- Person 89 ---\n",
            "Frames: 48 | Time: 1.60s\n",
            "Avg velocity: 2.0638\n",
            "Avg energy: 21.85\n",
            "Peak energy: 101.26\n",
            "\n",
            "--- Person 91 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 5.1393\n",
            "Avg energy: 52.14\n",
            "Peak energy: 132.73\n",
            "\n",
            "--- Person 92 ---\n",
            "Frames: 7 | Time: 0.23s\n",
            "Avg velocity: 3.2083\n",
            "Avg energy: 33.37\n",
            "Peak energy: 57.43\n",
            "\n",
            "--- Person 93 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 2.00\n",
            "Peak energy: 2.00\n",
            "\n",
            "--- Person 94 ---\n",
            "Frames: 25 | Time: 0.83s\n",
            "Avg velocity: 2.1491\n",
            "Avg energy: 22.63\n",
            "Peak energy: 71.34\n",
            "\n",
            "--- Person 95 ---\n",
            "Frames: 50 | Time: 1.67s\n",
            "Avg velocity: 2.0283\n",
            "Avg energy: 21.84\n",
            "Peak energy: 99.46\n",
            "\n",
            "--- Person 96 ---\n",
            "Frames: 14 | Time: 0.47s\n",
            "Avg velocity: 1.9136\n",
            "Avg energy: 19.74\n",
            "Peak energy: 44.36\n",
            "\n",
            "--- Person 99 ---\n",
            "Frames: 9 | Time: 0.30s\n",
            "Avg velocity: 4.6105\n",
            "Avg energy: 47.22\n",
            "Peak energy: 111.11\n",
            "\n",
            "--- Person 101 ---\n",
            "Frames: 108 | Time: 3.60s\n",
            "Avg velocity: 4.0116\n",
            "Avg energy: 41.53\n",
            "Peak energy: 249.29\n",
            "\n",
            "--- Person 103 ---\n",
            "Frames: 20 | Time: 0.67s\n",
            "Avg velocity: 35.7384\n",
            "Avg energy: 358.48\n",
            "Peak energy: 1496.08\n",
            "\n",
            "--- Person 104 ---\n",
            "Frames: 13 | Time: 0.43s\n",
            "Avg velocity: 54.0085\n",
            "Avg energy: 541.51\n",
            "Peak energy: 2665.65\n",
            "\n",
            "--- Person 106 ---\n",
            "Frames: 37 | Time: 1.23s\n",
            "Avg velocity: 7.0720\n",
            "Avg energy: 71.85\n",
            "Peak energy: 625.59\n",
            "\n",
            "--- Person 108 ---\n",
            "Frames: 65 | Time: 2.17s\n",
            "Avg velocity: 2.3761\n",
            "Avg energy: 25.09\n",
            "Peak energy: 99.12\n",
            "\n",
            "--- Person 109 ---\n",
            "Frames: 6 | Time: 0.20s\n",
            "Avg velocity: 1.9402\n",
            "Avg energy: 20.32\n",
            "Peak energy: 34.02\n",
            "\n",
            "--- Person 111 ---\n",
            "Frames: 3 | Time: 0.10s\n",
            "Avg velocity: 1.6069\n",
            "Avg energy: 16.57\n",
            "Peak energy: 26.71\n",
            "\n",
            "--- Person 112 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 11.1956\n",
            "Avg energy: 112.91\n",
            "Peak energy: 270.36\n",
            "\n",
            "--- Person 113 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 21.3043\n",
            "Avg energy: 214.67\n",
            "Peak energy: 561.74\n",
            "\n",
            "--- Person 114 ---\n",
            "Frames: 46 | Time: 1.53s\n",
            "Avg velocity: 3.0019\n",
            "Avg energy: 31.20\n",
            "Peak energy: 144.37\n",
            "\n",
            "--- Person 116 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 0.7452\n",
            "Avg energy: 7.95\n",
            "Peak energy: 15.40\n",
            "\n",
            "--- Person 118 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 3.2394\n",
            "Avg energy: 34.27\n",
            "Peak energy: 71.62\n",
            "\n",
            "--- Person 119 ---\n",
            "Frames: 62 | Time: 2.07s\n",
            "Avg velocity: 1.6105\n",
            "Avg energy: 17.36\n",
            "Peak energy: 164.17\n",
            "\n",
            "--- Person 120 ---\n",
            "Frames: 27 | Time: 0.90s\n",
            "Avg velocity: 4.1739\n",
            "Avg energy: 43.04\n",
            "Peak energy: 127.63\n",
            "\n",
            "--- Person 121 ---\n",
            "Frames: 39 | Time: 1.30s\n",
            "Avg velocity: 4.7898\n",
            "Avg energy: 48.74\n",
            "Peak energy: 219.58\n",
            "\n",
            "--- Person 122 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 2.4909\n",
            "Avg energy: 26.16\n",
            "Peak energy: 64.52\n",
            "\n",
            "--- Person 123 ---\n",
            "Frames: 28 | Time: 0.93s\n",
            "Avg velocity: 9.0440\n",
            "Avg energy: 91.58\n",
            "Peak energy: 360.54\n",
            "\n",
            "--- Person 125 ---\n",
            "Frames: 64 | Time: 2.13s\n",
            "Avg velocity: 2.3087\n",
            "Avg energy: 23.49\n",
            "Peak energy: 300.69\n",
            "\n",
            "--- Person 126 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 1.0940\n",
            "Avg energy: 11.44\n",
            "Peak energy: 21.55\n",
            "\n",
            "--- Person 129 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 1.4821\n",
            "Avg energy: 16.82\n",
            "Peak energy: 31.64\n",
            "\n",
            "--- Person 130 ---\n",
            "Frames: 15 | Time: 0.50s\n",
            "Avg velocity: 9.6154\n",
            "Avg energy: 97.42\n",
            "Peak energy: 221.06\n",
            "\n",
            "--- Person 131 ---\n",
            "Frames: 4 | Time: 0.13s\n",
            "Avg velocity: 1.8899\n",
            "Avg energy: 20.40\n",
            "Peak energy: 33.71\n",
            "\n",
            "--- Person 132 ---\n",
            "Frames: 43 | Time: 1.43s\n",
            "Avg velocity: 6.7650\n",
            "Avg energy: 68.44\n",
            "Peak energy: 281.71\n",
            "\n",
            "--- Person 133 ---\n",
            "Frames: 28 | Time: 0.93s\n",
            "Avg velocity: 5.8246\n",
            "Avg energy: 59.01\n",
            "Peak energy: 579.36\n",
            "\n",
            "--- Person 134 ---\n",
            "Frames: 12 | Time: 0.40s\n",
            "Avg velocity: 9.2253\n",
            "Avg energy: 93.59\n",
            "Peak energy: 167.45\n",
            "\n",
            "--- Person 137 ---\n",
            "Frames: 11 | Time: 0.37s\n",
            "Avg velocity: 6.2876\n",
            "Avg energy: 63.83\n",
            "Peak energy: 282.39\n",
            "\n",
            "--- Person 138 ---\n",
            "Frames: 3 | Time: 0.10s\n",
            "Avg velocity: 3.2761\n",
            "Avg energy: 34.26\n",
            "Peak energy: 58.64\n",
            "\n",
            "--- Person 140 ---\n",
            "Frames: 70 | Time: 2.33s\n",
            "Avg velocity: 7.4967\n",
            "Avg energy: 76.33\n",
            "Peak energy: 928.02\n",
            "\n",
            "--- Person 141 ---\n",
            "Frames: 39 | Time: 1.30s\n",
            "Avg velocity: 15.2192\n",
            "Avg energy: 153.19\n",
            "Peak energy: 1449.28\n",
            "\n",
            "--- Person 142 ---\n",
            "Frames: 7 | Time: 0.23s\n",
            "Avg velocity: 6.7667\n",
            "Avg energy: 69.02\n",
            "Peak energy: 142.26\n",
            "\n",
            "--- Person 143 ---\n",
            "Frames: 1 | Time: 0.03s\n",
            "Avg velocity: 0.0000\n",
            "Avg energy: 1.00\n",
            "Peak energy: 1.00\n",
            "\n",
            "--- Person 144 ---\n",
            "Frames: 9 | Time: 0.30s\n",
            "Avg velocity: 1.1400\n",
            "Avg energy: 11.68\n",
            "Peak energy: 39.03\n",
            "\n",
            "--- Person 147 ---\n",
            "Frames: 7 | Time: 0.23s\n",
            "Avg velocity: 1.3334\n",
            "Avg energy: 14.69\n",
            "Peak energy: 30.45\n",
            "\n",
            "--- Person 151 ---\n",
            "Frames: 14 | Time: 0.47s\n",
            "Avg velocity: 9.3067\n",
            "Avg energy: 94.42\n",
            "Peak energy: 305.24\n",
            "\n",
            "--- Person 152 ---\n",
            "Frames: 35 | Time: 1.17s\n",
            "Avg velocity: 5.2585\n",
            "Avg energy: 53.79\n",
            "Peak energy: 642.59\n",
            "\n",
            "--- Person 153 ---\n",
            "Frames: 34 | Time: 1.13s\n",
            "Avg velocity: 5.5772\n",
            "Avg energy: 56.57\n",
            "Peak energy: 557.14\n",
            "\n",
            "--- Person 154 ---\n",
            "Frames: 2 | Time: 0.07s\n",
            "Avg velocity: 0.7776\n",
            "Avg energy: 8.53\n",
            "Peak energy: 16.55\n",
            "\n",
            "==================================================\n",
            "COMPARATIVE ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Top 10 by Energy Level:\n",
            "  1. Person 10: 1385.88 (time: 0.2s)\n",
            "  2. Person 6: 1161.10 (time: 1.1s)\n",
            "  3. Person 11: 771.26 (time: 0.3s)\n",
            "  4. Person 9: 748.97 (time: 1.9s)\n",
            "  5. Person 80: 641.70 (time: 0.9s)\n",
            "  6. Person 104: 541.51 (time: 0.4s)\n",
            "  7. Person 37: 374.71 (time: 0.1s)\n",
            "  8. Person 103: 358.48 (time: 0.7s)\n",
            "  9. Person 31: 343.20 (time: 0.3s)\n",
            "  10. Person 79: 341.68 (time: 2.0s)\n",
            "\n",
            "Top 10 by Screen Time:\n",
            "  1. Person 101: 3.6s (108 frames)\n",
            "  2. Person 67: 3.4s (101 frames)\n",
            "  3. Person 19: 2.9s (87 frames)\n",
            "  4. Person 39: 2.8s (83 frames)\n",
            "  5. Person 3: 2.5s (74 frames)\n",
            "  6. Person 140: 2.3s (70 frames)\n",
            "  7. Person 108: 2.2s (65 frames)\n",
            "  8. Person 125: 2.1s (64 frames)\n",
            "  9. Person 119: 2.1s (62 frames)\n",
            "  10. Person 79: 2.0s (61 frames)\n"
          ]
        }
      ]
    }
  ]
}